{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"skoltech_logo.png\" alt=\"Skoltech\" width=60% height=60% />\n",
    "<h1 style=\"color:#333333; text-align:center; line-height: 0;\">Reinforcement Learning</h1>\n",
    "<h5 style=\"color:#333333; text-align:center;\">Course MA030422</h5>\n",
    "\n",
    "<h2 style=\"color:#A7BD3F;\">Lab 2</h2>\n",
    "\n",
    "***\n",
    "\n",
    "### Goal of this lab\n",
    "\n",
    "The purpose of this lab is to:\n",
    "1. Introduce you to the the gym-minigrid environment\n",
    "2. Practice creating and training neural networks in Pytorch for the purpose of applying them as function approximators in RL.\n",
    "3. Solve the gym-minigrid environment with a cross entropy RL algorithm\n",
    "\n",
    "### Components\n",
    "\n",
    "* **Section 1**: OpenAI <b style=\"color:blue;\">Gym-Mingrid</b> environment\n",
    "* **Section 2**: Neural networks in Pytorch\n",
    "    * Exercise 1 - Training a neural network\n",
    "        * Problem 1.1 (15 points) \n",
    "* **Section 3**: Neural networks in Pytorch\n",
    "    * Exercise 2 - Solving Minigrid 5x5\n",
    "        * Problem 2.1 (5 points)\n",
    "        * Problem 2.2 (15 points)\n",
    "        * Problem 2.3 (2 points)\n",
    "        \n",
    "Total points: 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\">Imports and Autograder</h2>\n",
    "\n",
    "***\n",
    "Take care of imports early on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# gym\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import gym_minigrid\n",
    "from gym_minigrid.minigrid import IDX_TO_OBJECT\n",
    "from gym_minigrid.wrappers import ImgObsWrapper, OneHotPartialObsWrapper\n",
    "\n",
    "# others\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from tensorboardX import SummaryWriter\n",
    "from IPython import display\n",
    "from grading_utilities import AnswerTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to track your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "lab2_answers = AnswerTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\">Section 1 - Environment</h2>\n",
    "\n",
    "***\n",
    "\n",
    "### Intro to OpenAI <i style=\"color:blue;\">gym minigrid</i> environment\n",
    "\n",
    "In lab 2 we will be exploring agent training in an grid world environment called *gym-minigrid*, seen [here](https://github.com/maximecb/gym-minigrid). The environment has the following characteristics <sup>[1]</sup>:\n",
    "\n",
    "<blockquote cite=\"https://github.com/maximecb/gym-minigrid\"><h4>Structure of the world:</h4>\n",
    "\n",
    "* The world is an NxM grid of tiles\n",
    "* Each tile in the grid world contains zero or one object\n",
    "* Cells that do not contain an object have the value None\n",
    "* Each object has an associated discrete color (string)\n",
    "* Each object has an associated type (string)\n",
    "* Provided object types are: wall, floor, lava, door, key, ball, box and goal\n",
    "* The agent can pick up and carry exactly one object (eg: ball or key)\n",
    "* To open a locked door, the agent has to be carrying a key matching the door's color\n",
    "\n",
    "#### Actions in the basic environment:\n",
    "\n",
    "* Turn left\n",
    "* Turn right\n",
    "* Move forward\n",
    "* Pick up an object\n",
    "* Drop the object being carried\n",
    "* Toggle (open doors, interact with objects)\n",
    "* Done (task completed, optional)\n",
    "* Default tile/observation encoding:\n",
    "\n",
    "<br />\n",
    "Each tile is encoded as a 3 dimensional tuple: (OBJECT_IDX, COLOR_IDX, STATE)</blockquote>\n",
    "\n",
    "### About the agent\n",
    "\n",
    "From <sup>[2]</sup>:\n",
    ">Observations in MiniGrid are partial and egocentric. By default, the agent sees a square of 7x7 tiles in the direction it is facing. These include the tile the agent is standing on. The agent cannot see through walls or closed doors. **The observations are provided as a tensor of shape 7x7x3**. However, note that these are not RGB images. Each tile is encoded using 3 integer values: one describing the type of object contained in the cell, one describing its color, and a state indicating whether doors are open, closed or locked. This compact encoding was chosen for space efficiency and to enable faster training. The fully observable RGB image view of the environments shown in this paper is provided for human viewing.\n",
    "\n",
    "To ease the computational burden of training (and for the sake of learning) - we will be training on a small 5x5 grid (it's really 3x3, as 5x5 includes walls):\n",
    "\n",
    "<img src=\"minigrid_5x5.png\" alt=\"Gym Minigrid\" width=30% height=30% />\n",
    "\n",
    "The picture below demonstrates an 8x8 grid (including walls):\n",
    "\n",
    "<img src=\"minigrid.png\" alt=\"Gym Minigrid\" width=40% height=40% />\n",
    "\n",
    "Notice the highlighted cells? That is actually the agent's view of the environment. As mentioned in the quoted text above, the agent's view is codifed as 7x7x3 tensor, and it appears as such (run the following cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0]],\n",
       "\n",
       "       [[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0]],\n",
       "\n",
       "       [[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0]],\n",
       "\n",
       "       [[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]],\n",
       "\n",
       "       [[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]],\n",
       "\n",
       "       [[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]],\n",
       "\n",
       "       [[2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [2, 5, 0],\n",
       "        [8, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify env name\n",
    "env_name = \"MiniGrid-Empty-6x6-v0\"\n",
    "\n",
    "# instantiate env\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# apply wrapper\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "# reset env to assign first obv\n",
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 2 dimensions of the tensor above have 7 elements each which signify the y and x coordinates, respectively, of the agent's observational field view. Note:\n",
    "* The y-axis starts from the top of the figure and moves downwards. \n",
    "* The agent's observational view may start **beyond** the confines of the grid\n",
    "\n",
    "The third dimension (of 3 elements) specifies <sup>[1]</sup>:\n",
    "* The type of object contained in the cell,\n",
    "* One describing its color,\n",
    "* And a state indicating whether doors are open, closed or locked.\n",
    "\n",
    "The object types (int) can be mapped to English representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'unseen',\n",
       " 1: 'empty',\n",
       " 2: 'wall',\n",
       " 3: 'floor',\n",
       " 4: 'door',\n",
       " 5: 'key',\n",
       " 6: 'ball',\n",
       " 7: 'box',\n",
       " 8: 'goal',\n",
       " 9: 'lava',\n",
       " 10: 'agent'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDX_TO_OBJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map the agent's integer-based observational-field-tensor to a unicode, string-based representation using the dict above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen']],\n",
       "\n",
       "       [['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen']],\n",
       "\n",
       "       [['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen']],\n",
       "\n",
       "       [['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen']],\n",
       "\n",
       "       [['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen']],\n",
       "\n",
       "       [['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen']],\n",
       "\n",
       "       [['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['wall', 'key', 'unseen'],\n",
       "        ['goal', 'empty', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen'],\n",
       "        ['empty', 'unseen', 'unseen']]], dtype='<U6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_obs = np.empty((7,7,3), dtype='<U6')\n",
    "\n",
    "for key, val in IDX_TO_OBJECT.items():\n",
    "    mapped_obs[obs == key] = val\n",
    "    \n",
    "mapped_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapped observations above confirm that the agent sees the goal in:\n",
    "* the 7th cell **down** (7th coordinate on the y-axis, which is the 6th indice of the 1st dimension of the `obs` tensor)\n",
    "* and the 4th cell **across** (4th cell on the x-axis, which is the 3rd indice of the 2nd dimension of the `obs` tensor)\n",
    "* Remember: The indices of container objects (lists, tuples, arrays, tensors, etc) in Python start from 0, not 1\n",
    "\n",
    "Below we retrieve the **indices** of the cell at Euclidean coordinates (7, 4) from the mapped observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x, _ = np.where(mapped_obs=='goal')\n",
    "y.item(), x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's review and confirm these numbers visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f95fde0bb00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(env.render(mode='rgb_array', highlight=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the agent's observational field of view starts beyond the confines of the **grid**, we see the numbers are correct: the green goal cell is in the 7th cell down (6th indice) and 4th cell across (3rd indice) from the observational field (0,0) coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our goal\n",
    "\n",
    "Our goal will be to train the agent to move to the green cell using function approximation with neural networks. Note that the gym-minigrid environment is customizable, and many interesting customizations are already provided in the repo above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\">Section 2 - Getting comfortable with Neural Networks</h2>\n",
    "\n",
    "***\n",
    "\n",
    "Before we get started with creating the algorithm to solve the environment, we need to understand how to create and train neural networks in Pytorch.\n",
    "\n",
    "### Quick primer on neural networks\n",
    "\n",
    "As discussed in homework 1, in RL there are 3 general types of functions:\n",
    "* value functions\n",
    "* policy function\n",
    "* reward function\n",
    "\n",
    "Unlike in homework 1, where we solved a discrete/finite state and action space MDP -- real world problems typically involve continuous state and action spaces, usually in more than 3 dimensions (more than 6 is rare).\n",
    "\n",
    "To solve environments with ‚ùó<font color=\"red\">continuous</font> state and action spaces (often that do not provide any explicit transition probabilities or reward functions), we use statistical models for function approximation.\n",
    "\n",
    "Of the various types of ML models available to us, the powerful abilities of neural networks make them among the more commonly selected for this task. This is because neural nets can model highly complex data, unstructured data, and are scalable to data size. Neural networks are often used in RL to approximate the **policy function**, specifically.\n",
    "\n",
    "üí° The use of **multi-layer** neural networks as function approximators in RL is what gives the name **Deep** in *Deep RL*.\n",
    "\n",
    "#### <font color=\"blue\">Side track:</font>\n",
    "If you're *completely* new to neural networks, checkout out the following links for a nice introduction:\n",
    "* [Neural networks and deep learning](http://neuralnetworksanddeeplearning.com/chap1.html)\n",
    "* [Tensorflow playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.39899&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "* [Intro to Deep Learning with Pytorch](https://pytorch.org/deep-learning-with-pytorch)\n",
    "* [Deep Learning Wizard](https://www.deeplearningwizard.com)\n",
    "\n",
    "Or message your instructors for good books on the subject.\n",
    "\n",
    "### Demo of a neural network\n",
    "\n",
    "The 3 most popular libraries for deep learning with Python are: Pytorch (developed by Facebook; open source), Tensorflow (developed by Google; open source), and Keras (built on top of Tensorflow; open source).\n",
    "\n",
    "We will be using Pytorch, as it is my favorite DL library and is usually preferred by research scientists and other individuals who like maximum control over neural architectures and ease of tensor operations. If you're new to Pytorch, check out the following [Tutorials](https://pytorch.org/tutorials/).\n",
    "\n",
    "Below, we demonstrate the basic structure of a 3 layer neural network with the aim to show you that it is simply a mathematical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensor\n",
    "\n",
    "Below we create a tensor that contains random integers (converted to 32-bit float values) in the shape of 5 rows and 3 columns. The rows represent **training examples** and the columns represent **features**. So we have 5 training examples, each with 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 16.,  1.],\n",
       "        [ 5.,  8.,  9.],\n",
       "        [ 7., 19.,  9.],\n",
       "        [ 7.,  8.,  5.],\n",
       "        [ 9., 16., 16.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear previous variables from memory\n",
    "try:\n",
    "    del x\n",
    "    del y\n",
    "    del env\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(999)\n",
    "\n",
    "# define number of training examples\n",
    "num_training_examples = 5\n",
    "\n",
    "# define number of features\n",
    "num_features = 3\n",
    "\n",
    "# define \"dataset\"\n",
    "dataset = torch.randint(low=0, high=20, size=(num_training_examples,num_features), dtype=torch.float32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neural network\n",
    "\n",
    "Next, we create a neural network with 3 linear layers. Check out Pytorch's docs on the [Linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture of binary logistic regression classifier\n",
    "class BinaryLogisticRegression(nn.Module):\n",
    "    def __init__(self, x_dim, out1 = 16, out2 = 32):\n",
    "        super(BinaryLogisticRegression, self).__init__()\n",
    "\n",
    "        # instantiate linear layers\n",
    "        self.linear1 = torch.nn.Linear(x_dim, out1)\n",
    "        self.linear2 = torch.nn.Linear(out1, out2)\n",
    "        self.linear3 = torch.nn.Linear(out2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply ReLU activation to linear layer 1\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        \n",
    "        # apply ReLU activation to linear layer 2\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        \n",
    "        # apply Sigmoid activation to linear layer 3\n",
    "        y = torch.sigmoid(self.linear3(x))\n",
    "        return y\n",
    "\n",
    "\n",
    "# instantiate the classifier\n",
    "neural_net = BinaryLogisticRegression(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass the dataset of size 5x3 to the network\n",
    "\n",
    "Now pass the dataset $X$ to the neural net to output $Y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4065],\n",
       "        [0.5661],\n",
       "        [0.5983],\n",
       "        [0.4973],\n",
       "        [0.6059]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = neural_net(dataset)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold\n",
    "Next, categorize $Y$ according to a threshold of 0.5 to classify the training examples into 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = torch.where(y > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">Note:</font> Remember - this model is not trained - this is just for example.\n",
    "\n",
    "Through the process of training the neural network on thousands of examples it learns to accurately map the input data $X$ to $Y$, and can be applied to multinomial classification as well as much more interesting supervised tasks.\n",
    "\n",
    "### What about network parameters?\n",
    "\n",
    "How many parameters/coefficients does the network have? After all, these are the very coefficients that are optimized to **accurately** map $X$ to  $Y$ (a neural network is not fancy code - but a statistical model).\n",
    "\n",
    "Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name linear1.weight: 48 elements\n",
      "Layer name linear1.bias: 16 elements\n",
      "Layer name linear2.weight: 512 elements\n",
      "Layer name linear2.bias: 32 elements\n",
      "Layer name linear3.weight: 32 elements\n",
      "Layer name linear3.bias: 1 elements\n",
      "Total parameters: 641\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "641"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to count number of parameters in Pytorch neural network\n",
    "def count_parameters(model, view_by_layer = False):\n",
    "    if view_by_layer is True:\n",
    "        tensor_list = model.state_dict().items()\n",
    "        total_params = [] \n",
    "        \n",
    "        for layer_name, tensor in tensor_list:\n",
    "            num_elements = torch.numel(tensor)\n",
    "            total_params.append(num_elements)\n",
    "            print(f'Layer name {layer_name}: {num_elements} elements')\n",
    "\n",
    "        print(f\"Total parameters: {sum(total_params)}\\n\")\n",
    "        \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_parameters = count_parameters(neural_net, view_by_layer = True)\n",
    "num_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "\n",
    "As we can see - this network of only 3 layers with 16, 32, and 1 hidden units each contains 641 parameters (including weights and biases). That's a long polynominal to make predictions for such a small 3-dimensional feature dataset.\n",
    "\n",
    "Neural networks with even a couple layers can be powerful approximators of policy and value functions in reinforcement learning. \n",
    "\n",
    "Next, let's train a neural network on the Wine dataset from Kaggle.\n",
    "\n",
    "### <font color=\"blue\">Exercise 1: Training a neural network</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a GPU is available to train on (which we're not counting on for this lab), we specify the device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the dataset\n",
    "\n",
    "We'll be performing a binary classification training task with the Wine Dataset, originally from [here](https://archive.ics.uci.edu/ml/datasets/wine). Notes:\n",
    "* Our dataset consists of both red and white wines. \n",
    "* There are 11 predictor variables and 1 target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the dataset\n",
    "\n",
    "Import the dataset from csv to pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (6497, 12)\n"
     ]
    }
   ],
   "source": [
    "# pandas df\n",
    "df = pd.concat([\n",
    "    pd.read_csv('winequality-red.csv', delimiter=';'),\n",
    "    pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "])\n",
    "\n",
    "num_features = df.shape[1]-1\n",
    "\n",
    "print(\"Data shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'quality' column is our y-label/target column. Let's view the distinct values for quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_labels = sorted(df.quality.unique())\n",
    "num_classes = len(sorted_labels)\n",
    "sorted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of wines in this dataset are categorized by discrete values ranging from 3 to 9.\n",
    "\n",
    "#### Convert labels for binary classification\n",
    "\n",
    "#### ‚ùó Classification Task: \n",
    "‚û°Ô∏è We will be predicting whether the quality of a wine is greater than or equal to 7. So we need to convert the y-labels into 2 classes (0 - less than 7, and 1 - greater than or equal to 7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4893    0.0\n",
       "4894    0.0\n",
       "4895    0.0\n",
       "4896    1.0\n",
       "4897    0.0\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 0 not in df['quality'].values:\n",
    "    df['quality'] = np.where((df.quality >= 7), 1.0 , 0.0)\n",
    "\n",
    "df['quality'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing\n",
    "\n",
    "Next, we need to do some data preprocessing:\n",
    "\n",
    "1. Split the data in to train-test groups\n",
    "2. Scale the data about the mean and sd\n",
    "3. Convert the dataframe data to tensors for Pytorch\n",
    "4. Create Pytorch dataloaders for batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data in to train-test groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = df.drop('quality', axis=1)\n",
    "y_labels = df['quality']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data about the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert df data to tensors for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = torch.as_tensor(x_train_scaled.astype(np.float32))\n",
    "y_train = torch.as_tensor(y_train.tolist(), dtype=torch.float32).unsqueeze(-1)\n",
    "x_test_scaled = torch.as_tensor(x_test_scaled.astype(np.float32))\n",
    "y_test = torch.as_tensor(y_test.tolist(), dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# concatenate into train and test sets\n",
    "train_set = torch.cat((x_train_scaled, y_train), dim=1)\n",
    "test_set = torch.cat((x_test_scaled, y_test), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataloaders for training with batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f95fdd8af28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a neural network\n",
    "\n",
    "Instantiate the neural network from above with 256 and 128 neurons in the first two layers, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryLogisticRegression(\n",
       "  (linear1): Linear(in_features=11, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BinaryLogisticRegression(num_features, 256, 128)\n",
    "\n",
    "# send the model to 'device' (GPU or CPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to compute accuracy\n",
    "\n",
    "The function below is called at the end of each epoch to compute the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model on the given dataset\n",
    "def compute_accuracy(model, batch):\n",
    "    with torch.no_grad():        \n",
    "        x_features = batch[:,:-1]\n",
    "        y_actual = batch[:,-1]\n",
    "        y_pred = (model.forward(x_features).flatten() > 0.5).float()\n",
    "        loss = criterion(y_pred, y_actual)\n",
    "        accuracy = sum((y_actual == y_pred).float()) / y_actual.numel()\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Problem 1.1</font>\n",
    "\n",
    "#### üéØ Task 1: create a training loop for the model. Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vs/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/vs/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([77])) that is different to the input size (torch.Size([77, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-50c5631c92a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m### YOUR SOLUTION ABOVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: {epoch} - running_loss: {running_loss:.3f} - train_accuracy: {train_accuracy:.2%}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-581e5e972463>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mx_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0my_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "    \"\"\" Instructions:\n",
    "        \n",
    "        Implement:\n",
    "        * a loss function in the 'criterion' variable \n",
    "        * an optimizer in the 'optimizer' variable\n",
    "        * number of epochs in `n_epochs`\n",
    "        \n",
    "        Notes:\n",
    "        * for criterion, use BinaryCrossEntropy: https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\n",
    "        * for optimizer:, use Adam: https://pytorch.org/docs/stable/optim.html#torch.optim.Adam\n",
    "        \n",
    "    \"\"\"\n",
    "    ### YOUR SOLUTION BELOW\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    ### YOUR SOLUTION ABOVE\n",
    "    n_epochs = 150\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        \"\"\" Instructions:\n",
    "        \n",
    "            Implement a training loop for the model.\n",
    "            \n",
    "            Hint: it will look a lot like the `compute_accuracy` method but you need to loop\n",
    "            over all of the batches in trainloader.\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR SOLUTION BELOW\n",
    "        for i, batch in enumerate(trainloader):\n",
    "            x_features = batch[:,:-1]\n",
    "            y_actual = batch[:,-1]\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_features)\n",
    "        \n",
    "            loss = criterion(y_pred, y_actual)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        ### YOUR SOLUTION ABOVE\n",
    "            \n",
    "        train_accuracy = compute_accuracy(model, trainloader)\n",
    "        print(f\"epoch: {epoch} - running_loss: {running_loss:.3f} - train_accuracy: {train_accuracy:.2%}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy\n",
    "* Your model should achieve an accuracy on the <font color=\"red\">test set</font> of at least => **85%** in 150 epochs. If it fails to achieve this threshold, think of ways to improve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 79.11%\n"
     ]
    }
   ],
   "source": [
    "sum_batch_test_accuracy = 0\n",
    "\n",
    "for i, test_batch in enumerate(testloader, 1):\n",
    "    sum_batch_test_accuracy += compute_accuracy(model, test_batch)\n",
    "\n",
    "all_batches_test_accuracy = sum_batch_test_accuracy / i\n",
    "\n",
    "print(f\"Accuracy on test set: {all_batches_test_accuracy.item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to save your answer for problem 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "lab2_answers.record('problem_1-1', all_batches_test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Exercise 2: Solving minigrid 5x5</font>\n",
    "\n",
    "In this exercise we will solve the 5x5 (really: 3x3) gym-minigrid environment presented in section 1 with a neural network trained with cross entropy loss. For multi-class (C > 2), discrete probability distributions, cross entropy loss is defined as: \n",
    "\n",
    "$$C(p,q) = -\\sum_{x\\in{X}}p(x)\\log{q(x)}$$\n",
    "\n",
    "By now you are familiar with the basics of working with OpenAI environments, but let's refresh our memory on the general cycle of agent learning. The agent:\n",
    "1. Receives observations\n",
    "2. Selects an action (based on policy function or value function)\n",
    "3. Takes a step in the environment with the action\n",
    "4. Receives a reward and the new state of the environment.\n",
    "\n",
    "#### In this exercise, we will focus on approximating the policy function with neural networks.\n",
    "\n",
    "Our overall algorithm will be the following:\n",
    "\n",
    "1. Create a neural network (NN) to approximate policy\n",
    "2. Build a buffer of **episodes** of experiences $(s_t, a_t, r_t)$, with the NN selecting actions for each step \n",
    "3. Filter the buffer to keep only episodes with the most rewards (specified by a percentile).\n",
    "4. Train the neural network to learn the optimal policy from the best episodes (from step #3)\n",
    "5. Repeat until a threshold of reward is achieved\n",
    "\n",
    "### <font color=\"blue\">Problem 2.1</font>\n",
    "\n",
    "#### üéØ Task 1: Create a neural network with 2 layers below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num linear layers:  2\n"
     ]
    }
   ],
   "source": [
    "class PolicyNN(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        ### YOUR SOLUTION BELOW\n",
    "        self.linear1 = torch.nn.Linear(obs_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, n_actions)\n",
    "        ### YOUR SOLUTION ABOVE\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 3:\n",
    "            x = x.flatten().unsqueeze(0)\n",
    "        elif x.ndim > 3:\n",
    "            x = x.flatten(start_dim=1)\n",
    "\n",
    "        ### YOUR SOLUTION BELOW\n",
    "        # apply ReLU activation to linear layer 1\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        \n",
    "        # apply ReLU activation to linear layer 2\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        ### YOUR SOLUTION ABOVE\n",
    "        return x\n",
    "    \n",
    "test_net = PolicyNN(16, 128, 7)\n",
    "n_lin_layers = len(set(map(lambda layer: layer.split(\".\")[0], test_net.state_dict().keys())))\n",
    "print(\"Num linear layers: \", n_lin_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to save your answer for problem 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "lab2_answers.record('problem_2-1', n_lin_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Problem 2.2</font>\n",
    "\n",
    "Problem 2.2 contains 2 tasks:\n",
    "\n",
    "**<font color=\"blue\">Task 1</font>**: Fill in the code specified the `_iterate_batches` method (designated by comments).\n",
    "\n",
    "#### Hints:\n",
    "* Study all of the variables and methods of the class to get an intuiton about the algorithm works as a whole\n",
    "* Read about [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)\n",
    "* Read about Pytorch's [Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax) function\n",
    "* Read about Pytorch's [Cross Entropy loss function](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax)\n",
    "* Recall the definition of a **experience, trajectory, and episode** from homework 1.\n",
    "* Use `np.random.choice`\n",
    "\n",
    "**<font color=\"blue\">Task 2</font>**: Implement network training in  `run_training` method.\n",
    "* Use your knowledge from problem 1.1\n",
    "\n",
    "#### üéØ Implement both tasks 1 and 2 below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyAgent:\n",
    "    def __init__(self, env_name, hidden_size=128, batch_size = 100, percentile = 30, gamma = 0.95, reward_threshold=0.80, loss_threshold = 0.5):\n",
    "        self.env = gym.make(env_name)\n",
    "        #self.env = OneHotPartialObsWrapper(self.env)\n",
    "        self.env = ImgObsWrapper(self.env)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.percentile = percentile\n",
    "        self.gamma = gamma\n",
    "        self.reward_threshold = reward_threshold\n",
    "        self.all_batches = []\n",
    "        self.reward_mean = 0\n",
    "        self.Episode = namedtuple('Episode', field_names=['reward', 'trajectory'])\n",
    "        self.Experience = namedtuple('Experience', field_names=['state', 'action'])\n",
    "        self.loss = 100\n",
    "        self.loss_threshold = 0.75\n",
    "\n",
    "        obs_size = np.prod(self.env.observation_space.shape)\n",
    "        n_actions = self.env.action_space.n\n",
    "\n",
    "        self.policy = PolicyNN(obs_size, hidden_size, n_actions)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(params=self.policy.parameters(), lr=1e-2)\n",
    "\n",
    "    def render_env(self):\n",
    "        plt.imshow(self.env.render(mode='rgb_array', highlight=False))\n",
    "\n",
    "    def video_callable(self, episode_id):\n",
    "        episode_num = episode_id+1\n",
    "        boolean = True\n",
    "        return boolean\n",
    "        \n",
    "    def _iterate_batches(self, evaluate = False):\n",
    "        batch_of_episodes = []\n",
    "        episode_reward = 0.0\n",
    "        trajectory = []\n",
    "        state = self.env.reset()\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        if evaluate:\n",
    "            i = 1\n",
    "        \n",
    "        while True:            \n",
    "            state_tensor = torch.FloatTensor([state])\n",
    "            \n",
    "            ### FILL IN YOUR SOLUTION BELOW\n",
    "            \n",
    "            action_probs = softmax(self.policy.forward(state_tensor)).flatten()\n",
    "            # pass state tensor to policy neural network, wrap in a softmax to get probabilities, and then flatten the output\n",
    "            \n",
    "            if self.loss < self.loss_threshold:\n",
    "                # get argmax of action probs; make sure to call item()\n",
    "                action = torch.argmax(action_probs).item()\n",
    "            else:\n",
    "                # detach action probs, convert to numpy array #DONE\n",
    "                action_probs = action_probs.detach().numpy()\n",
    "                                \n",
    "                # sample action from action probs\n",
    "                action = np.random.choice(self.env.action_space.n, p = action_probs)\n",
    "            \n",
    "            # take step with action   \n",
    "            new_state, reward, is_done, info = self.env.step(action)\n",
    "            \n",
    "            # increment episode_reward\n",
    "            episode_reward += reward\n",
    "            \n",
    "            # append experience to trajectory\n",
    "            trajectory.append(self.Experience(new_state, action))\n",
    "            #print(self.Experience(new_state, action))\n",
    "\n",
    "            ### FILL IN YOUR SOLUTION ABOVE\n",
    "            \n",
    "            if is_done:\n",
    "                if evaluate == False:\n",
    "                    batch_of_episodes.append(self.Episode(reward=episode_reward, trajectory=trajectory))\n",
    "                    episode_reward = 0.0\n",
    "                    trajectory = []\n",
    "                    new_state = self.env.reset()\n",
    "                    \n",
    "                    if len(batch_of_episodes) == self.batch_size:\n",
    "                        yield batch_of_episodes\n",
    "                        batch_of_episodes = []\n",
    "\n",
    "                else:\n",
    "                    if i == 3:\n",
    "                        print(\"...Done recording.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        new_state = self.env.reset()\n",
    "                        i += 1\n",
    "            \n",
    "            state = new_state\n",
    "\n",
    "    def _filter_batch(self, batch_of_episodes):\n",
    "        disc_rewards = list(map(lambda episode: episode.reward * (self.gamma ** len(episode.trajectory)), batch_of_episodes))\n",
    "        reward_bound = np.percentile(disc_rewards, self.percentile)\n",
    "\n",
    "        states = []\n",
    "        actions = []\n",
    "        top_batches = []\n",
    "\n",
    "        for episode, discounted_reward in zip(batch_of_episodes, disc_rewards):\n",
    "            if discounted_reward > reward_bound:\n",
    "                states.extend(map(lambda experience: experience.state, episode.trajectory))\n",
    "                actions.extend(map(lambda experience: experience.action, episode.trajectory))\n",
    "                top_batches.append(episode)\n",
    "        \n",
    "        return top_batches, torch.FloatTensor(states), torch.LongTensor(actions), reward_bound\n",
    "\n",
    "    def run_training(self, increment_ptl_by = 1, record_video=True):\n",
    "        try:\n",
    "            for iter_no, batch_of_episodes in enumerate(self._iterate_batches(), start=1):\n",
    "                self.reward_mean = float(np.mean(list(map(lambda episode: episode.reward, batch_of_episodes))))\n",
    "\n",
    "                self.all_batches.extend(batch_of_episodes)\n",
    "                \n",
    "                top_batches, states, best_actions, reward_bound = self._filter_batch(self.all_batches)\n",
    "                \n",
    "                if not top_batches:\n",
    "                    print(f\"iter {iter_no}: top_batches empty, continuing to next iteration... Percentile = {self.percentile}\")\n",
    "                    self.percentile -= 5\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                self.all_batches = top_batches\n",
    "\n",
    "                ### YOUR SOLUTION BELOW\n",
    "                action_pred = self.policy.forward(states)            \n",
    "                self.loss = self.criterion(action_pred, best_actions)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                self.loss.backward()\n",
    "                self.optimizer.step()\n",
    "                        \n",
    "                ### YOUR SOLUTION ABOVE\n",
    "                \n",
    "                print(f\"{iter_no}, loss: {self.loss.item():.3f}, reward_mean: {self.reward_mean:.3f}, percentile: {self.percentile}, n_batches: {len(self.all_batches)}\")\n",
    "    \n",
    "                \n",
    "                if self.reward_mean >= self.reward_threshold:\n",
    "                    print(\"Solved!\")\n",
    "\n",
    "                    if record_video:\n",
    "                        print(\"Recording videos...\")\n",
    "                        self.env = wrappers.Monitor(self.env, \"./video\", force=True, video_callable=lambda episode_id: True)\n",
    "                        \n",
    "                        for _ in self._iterate_batches(evaluate=True):\n",
    "                            break\n",
    "                    \n",
    "                    break\n",
    "                else:\n",
    "                    if self.percentile < 80:\n",
    "                        self.percentile += increment_ptl_by\n",
    "                    \n",
    "                    else:\n",
    "                        self.percentile = 60\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training cancelled.\")\n",
    "            \n",
    "        except NotImplementedError:\n",
    "            print(\"Solution incomplete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation\n",
    "\n",
    "* Expect the level below to be solved in 4 to 15 iterations.\n",
    "* This code records 3 videos of the agent performing after training (i.e. 3 episodes). \n",
    "    * **Note**: Even if the agent has a high *mean reward* during training, <font color=\"red\">it doesn't mean it will solve the level on every episode during the recording</font>. This is an inherent problem with such algorithms and we will discuss why in future lessons.\n",
    "* By default, the code below will create a /video/ folder (in the current directory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, loss: 1.824, reward_mean: 0.236, percentile: 70, n_batches: 30\n",
      "2, loss: 2.595, reward_mean: 0.053, percentile: 71, n_batches: 38\n",
      "3, loss: 4.516, reward_mean: 0.032, percentile: 72, n_batches: 39\n",
      "4, loss: 1.550, reward_mean: 0.471, percentile: 73, n_batches: 38\n",
      "5, loss: 1.969, reward_mean: 0.109, percentile: 74, n_batches: 34\n",
      "6, loss: 1.946, reward_mean: 0.168, percentile: 75, n_batches: 34\n",
      "7, loss: 1.945, reward_mean: 0.190, percentile: 76, n_batches: 28\n",
      "8, loss: 1.949, reward_mean: 0.202, percentile: 77, n_batches: 28\n",
      "9, loss: 1.944, reward_mean: 0.221, percentile: 78, n_batches: 26\n",
      "10, loss: 1.946, reward_mean: 0.217, percentile: 79, n_batches: 26\n",
      "11, loss: 1.946, reward_mean: 0.172, percentile: 80, n_batches: 23\n",
      "12, loss: 1.946, reward_mean: 0.222, percentile: 60, n_batches: 49\n",
      "13, loss: 1.946, reward_mean: 0.218, percentile: 61, n_batches: 58\n",
      "14, loss: 1.946, reward_mean: 0.183, percentile: 62, n_batches: 60\n",
      "15, loss: 1.946, reward_mean: 0.248, percentile: 63, n_batches: 59\n",
      "16, loss: 1.946, reward_mean: 0.279, percentile: 64, n_batches: 56\n",
      "17, loss: 1.946, reward_mean: 0.177, percentile: 65, n_batches: 54\n"
     ]
    }
   ],
   "source": [
    "env_name = \"MiniGrid-Empty-5x5-v0\"\n",
    "\n",
    "agent = CrossEntropyAgent(env_name, percentile=70, reward_threshold=0.80)\n",
    "agent.run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to track your answers and to save your answer for problem 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "lab2_answers.record('problem_2-2', agent.reward_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take some time to think\n",
    "\n",
    "If you run this algorithm numerous times, you'll notice it's performance varies quite a bit. Imagine if such an algorithm were implemented in a medical setting; it would be a  disaster.\n",
    "\n",
    "One of its core weaknesses is the need to guess and test hyperparameters, most importantly the `loss_threshold` that we use to either sample actions from the policy, or alternatively, to select the maximum probability action.\n",
    "\n",
    "And even *after* the trial and error of selecting the \"best\" hyperparameters, the performance of the algorithm **still** varies greatly.\n",
    "\n",
    "### <font color=\"blue\">Problem 2.3</font>\n",
    "\n",
    "**Question**: Do you think there is a better way to solve environments such as this one (finite state-spaces), and **especially** continuous state-spaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Replace 'None' with 1 (for yes) or 0 (for no)\n",
    "\"\"\"\n",
    "### YOUR ANSWER BELOW\n",
    "answer = None\n",
    "### YOUR ANSWER ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "Run this cell to track your answers and to save your answer for problem 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "lab2_answers.record('problem_2-3', answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading: Submit your answers</font>\n",
    "Enter your first and last name in the cell below and then run it to save your answers for this lab to a JSON file. The file is saved to the same directory as this notebook. After the file is created, upload the JSON file to the assignment page on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem_1-1': 0.7911458015441895, 'problem_2-1': 2, 'problem_2-2': 0.18768, 'problem_2-3': None}\n"
     ]
    }
   ],
   "source": [
    "lab2_answers.print_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_name = \"lab_2\"\n",
    "first_name = \"YOUR_FIRST_NAME\" # Use proper capitalization\n",
    "last_name = \"YOUR_LAST_NAME\" # Use proper capitalization\n",
    "\n",
    "lab2_answers.save_to_json(assignment_name, first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"8F00FF\">Optional Exercise 3</font>: A tougher environment?\n",
    "\n",
    "Let's try running the cross entropy algorithm above on a tougher environment ([more levels here](https://github.com/maximecb/gym-minigrid)), namely with lava lakes that the agent has to avoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_name = \"MiniGrid-DistShift1-v0\"\n",
    "\n",
    "agent2 = CrossEntropyAgent(env_name, percentile=60, reward_threshold=0.75)\n",
    "agent2.render_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Note:</font>\n",
    "* Watch out for the \"BrokenPipeError\" - which is a known bug in OpenAI's Monitor Wrapper that has to do with multithreading.\n",
    "* If you experience this error (usually at around 17 iterations), you'll need to restart your kernel and run Exercise 3 again. Remember to execute all of the imports and other dependencies in the notebook as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2.run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "Think about the question - is there a more (mathematically) rigorous way to design algorithms that guarantee performance, especially for use in real-life applications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions?\n",
    "\n",
    "Reach out to your instructors on Piazza.\n",
    "\n",
    "### Sources\n",
    "\n",
    "***\n",
    "\n",
    "[1] Gym-minigrid, https://github.com/maximecb/gym-minigrid\n",
    "\n",
    "[2] Chevalier-Boisvert, M., Bahdanau, D., Lahlou, S., Willems, L., Saharia, C., Nguyen, T. H. & Bengio, Y. (2019). BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning.. ICLR (Poster), : OpenReview.net. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
